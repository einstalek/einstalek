<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Paper on Underground Notes</title>
    <link>https://einstalek.github.io/tags/paper/</link>
    <description>Recent content in Paper on Underground Notes</description>
    <generator>Hugo -- 0.133.0</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://einstalek.github.io/tags/paper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Text-Guided 3D Face Synthesis: Paper Break-Down</title>
      <link>https://einstalek.github.io/posts/sds-faceg2e/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://einstalek.github.io/posts/sds-faceg2e/</guid>
      <description>In this post, I want to revisit Score Samping Distillation (SDS) for 3D head synthesis. Having recently found this paper, I discovered several ideas on how to properly generate textures with SDS. In my previous post on this topic I was mentioning that it was particularly complicated to generate clean face textures.
Figure 1: Image from the paper: faceg2e pipeline
Geometry phase First thing to notice is that the pipeline is split into two parts: geometry generation and then texture generation.</description>
    </item>
    <item>
      <title>AUV-Net: Paper Break-down, Part 1</title>
      <link>https://einstalek.github.io/posts/auvnet-2d/auvnet-2d/</link>
      <pubDate>Thu, 18 May 2023 00:00:00 +0000</pubDate>
      <guid>https://einstalek.github.io/posts/auvnet-2d/auvnet-2d/</guid>
      <description>Aligning mesh textures with different topologies could be a fantastic feature for any 3D project. This would unlock numerous possibilities, such as texture transfer or novel texture generation. That’s precisely what the AUV-Net paper by Nvidia addresses. Let’s review the paper to understand its primary concepts, implement it from scratch, and see if we can achieve results similar to those in the paper.
Figure 1: Texture transfer with AUV-Net, image from the paper</description>
    </item>
  </channel>
</rss>
