<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>How To Visually Evaluate Image Classifier Using StyleGAN2 | Underground Notes</title>
<meta name="keywords" content="classifier, gan, latent">
<meta name="description" content="In this article, we’ll be evaluating an image classifier by exploring StyleGAN2 latent space. We’ll look at the performance of a hairstyle classifier that we use in Ready Player Me.
StyleGAN2 is a generative model architecture demonstrating state-of-the-art image generation. Code of the model and pre-trained weights can be found, for example, in this repo, alongside generated examples across various domains.
Figure 1: Examples generated with StyleGAN2
First, what are we going to do?">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/hairstyle-classifier/hairstyle-classifier/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b61fcfd045e796a8b2d82921640c6460592faab5e5c2c76d0ba1c0018405cbfa.css" integrity="sha256-th/P0EXnlqiy2CkhZAxkYFkvqrXlwsdtC6HAAYQFy/o=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/hairstyle-classifier/hairstyle-classifier/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Underground Notes (Alt + H)">Underground Notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How To Visually Evaluate Image Classifier Using StyleGAN2
    </h1>
    <div class="post-meta"><span title='2023-11-12 00:00:00 +0000 UTC'>November 12, 2023</span>&nbsp;·&nbsp;4 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#small-intro-to-stylegan2" aria-label="Small intro to StyleGAN2">Small intro to StyleGAN2</a></li>
                <li>
                    <a href="#cnn-classifier--stylegan" aria-label="CNN Classifier &#43; StyleGAN">CNN Classifier + StyleGAN</a></li>
                <li>
                    <a href="#results" aria-label="Results">Results</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In this article, we’ll be evaluating an image classifier by exploring StyleGAN2 latent space. We’ll look at the performance of a hairstyle classifier that we use in <a href="https://readyplayer.me/">Ready Player Me</a>.</p>
<p>StyleGAN2 is a generative model architecture demonstrating state-of-the-art image generation. Code of the model and pre-trained weights can be found, for example, in this <a href="https://github.com/rosinality/stylegan2-pytorch">repo</a>, alongside generated examples across various domains.</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/faces.png#center"
         alt="Figure 1: Examples generated with StyleGAN2"/> <figcaption>
            <p>Figure 1: Examples generated with StyleGAN2</p>
        </figcaption>
</figure>

<p>First, what are we going to do? The idea is pretty simple. Having a hairstyle classifier, we’ll search through StyleGAN2 latent space to find directions in it corresponding to each of our classes.</p>
<p>It’s not the best way to test your model if you need some good-old metrics like accuracy, F1-score, and others. But, this way, you get to see what kind of pictures actually trigger your model to predict a certain class. So, it’s going to be more visual.</p>
<h3 id="small-intro-to-stylegan2">Small intro to StyleGAN2<a hidden class="anchor" aria-hidden="true" href="#small-intro-to-stylegan2">#</a></h3>
<p>Let’s not go too deep into technical details, but here’s what you need to know. If you look at the StyleGAN2 architecture below, you would see that the noise input Z is first mapped to the style space W, which then is fed to the Generator.</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/stylegan.png#center"
         alt="Figure 2: StyleGAN2 architecture" height="512"/> <figcaption>
            <p>Figure 2: StyleGAN2 architecture</p>
        </figcaption>
</figure>

<p>Manipulating input to StyleGAN in the W+ space may be used to generate images from a certain domain. For example, it’s done in StyleCLIP:</p>
<figure class="custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/samples.png"
         alt="Figure 3: Variance in StyleGAN2 space"/> <figcaption>
            <p>Figure 3: Variance in StyleGAN2 space</p>
        </figcaption>
</figure>

<h3 id="cnn-classifier--stylegan">CNN Classifier + StyleGAN<a hidden class="anchor" aria-hidden="true" href="#cnn-classifier--stylegan">#</a></h3>
<p>Let’s take our hairstyle classifier and consider one of its classes. Say, “curly bob with fringe”. The goal is to check whether the classifier is triggered by the right high-level features presented in images.</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/training-set.png#center"
         alt="Figure 4: Examples from training dataset, &lsquo;curly bob with fringe&rsquo;"/> <figcaption>
            <p>Figure 4: Examples from training dataset, &lsquo;curly bob with fringe&rsquo;</p>
        </figcaption>
</figure>

<p>What we want to do is to make our StyleGAN generate pictures that will maximize the probability of the “curly bob with fringe” class predicted by our hairstyle model. And hopefully, we’re going to see images similar to the ground truth ones.
By tuning the direction in latent space, we&rsquo;re optimizing two losses:</p>
<ol>
<li>
<p>Classifier loss, which could be cross-entropy between what the hairstyle classifier predicts and the label of the desired class;</p>
</li>
<li>
<p>Identity loss, to preserve the person’s identity while changing only their hairstyle. Sort of like a regularization. For that, we can use, for example, a pre-trained <a href="https://github.com/TreB1eN/InsightFace_Pytorch">InsightFace</a>.</p>
</li>
</ol>
<h3 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h3>
<p>After running tuning for multiple classes, we can now check how well we managed to capture those style directions. For that, we’ll generate a sequence of images adding the learned direction vector to the latent vector with some weight.</p>
<p>Combining these sequences of images into GIFs, we got something like this for the “curly bob with fringe” class:</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/interpolation.gif#center"
         alt="Figure 5: Interpolation in W&#43; space for &lsquo;curly bob with fringe&rsquo; hairstyle"/> <figcaption>
            <p>Figure 5: Interpolation in W+ space for &lsquo;curly bob with fringe&rsquo; hairstyle</p>
        </figcaption>
</figure>

<p>Remember, we got these results simply by maximizing our classifier’s probabilities for a certain class. This shows quite visually what kind of high-level features trigger the classifier to predict a particular class.</p>
<p>Let’s see the same kind of visualizations for one more class, long straight hair with fringe:</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/interpolation-1.gif#center"
         alt="Figure 6: Interpolation in W&#43; space for &rsquo;long straight with fringe&rsquo; hairstyle"/> <figcaption>
            <p>Figure 6: Interpolation in W+ space for &rsquo;long straight with fringe&rsquo; hairstyle</p>
        </figcaption>
</figure>

<p>These are both classes that our hairstyle model seems to have learned correctly. With face features not changing much during the interpolation in the W+ space, we see hairstyles in our examples change exactly how they are supposed to.</p>
<p>But of course, sometimes models overfit or learn to detect something else but the real target features. To illustrate one of those cases, let’s look at interpolation examples for a class of “long African braids”.</p>
<figure class="align-center custom-caption">
    <img loading="lazy" src="/posts/hairstyle-classifier/interpolation-2.gif#center"
         alt="Figure 7: Interpolation in W&#43; space for &rsquo;long African braids&rsquo; hairstyle"/> <figcaption>
            <p>Figure 7: Interpolation in W+ space for &rsquo;long African braids&rsquo; hairstyle</p>
        </figcaption>
</figure>

<p>Here, we see that maximizing the hairstyle model’s confidence for this hairstyle class also causes changes in skin color. This may suggest, for example, that the dataset is unbalanced for this particular class. Racial disbalance in the dataset can easily cause such behavior and should be dealt with by collecting more images with a more diverse representation.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/classifier/">Classifier</a></li>
      <li><a href="http://localhost:1313/tags/gan/">Gan</a></li>
      <li><a href="http://localhost:1313/tags/latent/">Latent</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Underground Notes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
